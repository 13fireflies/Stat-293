---
title: "293 Project Simulations"
author: "Jason"
date: '2022-04-10'
output: pdf_document
---

To-Dos:
- try other matching methods and compute their complexity
-- make sure profmatch works
NOTE: cplex code was commented out!
- need data generation method for feature variable selection
- try other feature variable selection methods
-- encode OAL


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup:

## Packages:
```{r setup, include=FALSE}
# use (.packages()) to check if a package is properly loaded for your session
library("designmatch")
library("ggplot2")
library("mvtnorm")
library("Matrix")
library("dplyr")
library("lqa")
library("MASS")
```


## Shortreed and Ertefaie: OAL
Functions for Shortreed and Ertefaie's OAL (taken directly from their supplemental code).
```{r setup, include=FALSE}
### define some functions for generating data, ATE estimates, and the wAMD
expit = function(x){ 
 pr = ( exp(x) / (1+exp(x)) ) 
 return(pr)
}
ATE_est = function(fY,fw,fA){
 t_ATE = fY*fw
 tt_ATE = ( ( sum(t_ATE[fA==1]) / sum(fw[fA==1]) ) - ( sum(t_ATE[fA==0]) /  sum(fw[fA==0]) ) )
 return(tt_ATE) 
}
create_weights = function(fp,fA,fw){
 fw = (fp)^(-1)
 fw[fA==0] = (1 - fp[fA==0])^(-1)
 return(fw)
}
wAMD_function = function(DataM,varlist,trt.var,wgt,beta){
 trt = untrt = diff_vec = rep(NA,length(beta)) 
 names(trt) = names(untrt) = names(diff_vec) = varlist
 for(jj in 1:length(varlist)){ 
  this.var = paste("w",varlist[jj],sep="") 
  DataM[,this.var] = DataM[,varlist[jj]] * DataM[,wgt] 
  trt[jj] = sum( DataM[DataM[,trt.var]==1, this.var ]) / sum(DataM[DataM[,trt.var]==1, wgt]) 
  untrt[jj] = sum(DataM[DataM[,trt.var]==0, this.var]) / sum(DataM[DataM[,trt.var]==0, wgt]) 
  diff_vec[jj] = abs( trt[jj] - untrt[jj] ) 
 } 
 wdiff_vec = diff_vec * abs(beta) 
 wAMD = c( sum(wdiff_vec))
 ret = list( diff_vec = diff_vec, wdiff_vec = wdiff_vec, wAMD = wAMD )
 return(ret) 
}
```

## ProfMatch:

```{r setup, include=FALSE}
# From Eric's paper
.oneprob_profmatch <- function(level, t_ind, mom, solver){
  mom_covs <- mom$covs
  mom_tols <- mom$tols
  mom_targets <- mom$targets
  
  if (is.null(solver)) {
    solver = 'glpk'
    t_max = 60 * 15
    approximate = 1
  } else {
    t_max = solver$t_max
    approximate = solver$approximate
    trace = solver$trace
    round_cplex = solver$round_cplex
    solver = solver$name
  }
  
  .mom_covs <- mom_covs[which(t_ind == level),]
  
  #! Generate the parameters
  cat(format("  Building the matching problem..."), "\n")
  prmtrs = .problemparameters_profmatch(.mom_covs, mom_tols, mom_targets)
  
  n = prmtrs$n
  n_dec_vars = prmtrs$n_dec_vars
  cvec = prmtrs$cvec
  Amat = prmtrs$Amat
  bvec = prmtrs$bvec
  sense = prmtrs$sense
  vtype = prmtrs$vtype
  
  #! Find matches and calculate the elapsed time
  #! Gurobi
  if (solver == "gurobi") {
    #library(gurobi)
    if (requireNamespace('gurobi', quietly=TRUE)) {
      cat(format("  Gurobi optimizer is open..."), "\n")
      model = list()
      model$modelsense = 'max'
      model$obj = cvec
      model$A = Amat
      model$sense = rep(NA, length(sense))
      model$sense[sense=="E"] = '='
      model$sense[sense=="L"] = '<='
      model$sense[sense=="G"] = '>='
      model$rhs = bvec
      model$vtypes = vtype
      
      t_lim = list(TimeLimit = t_max, OutputFlag = trace)
      
      cat(format("  Finding the optimal matches..."), "\n")
      ptm = proc.time()
      out = gurobi::gurobi(model, t_lim)
      time = (proc.time()-ptm)[3]
      
      if (out$status == "INFEASIBLE") {
        cat(format("  Error: problem infeasible!"), "\n")
        obj_total = NA
        obj_dist_mat = NA
        id = NA
        time = NA
      }
      
      if (out$status ==  "OPTIMAL" || out$status == "TIME_LIMIT") {
        if (out$status == "OPTIMAL") {
          cat(format("  Optimal matches found"), "\n")
        }
        
        else {
          cat(format("  Time limit reached, best suboptimal solution given"), "\n")
        }
        
        #! Matched units indexes
        id = (1:n_dec_vars)[out$x==1]
        
        #! Optimal value of the objective function
        obj_total = out$objval   
      }
    } else {
      stop('Required solver not installed')
    }
    
  }
  
  #! CPLEX
  else if (solver == "cplex") {
    #library(Rcplex)
    if (requireNamespace('Rcplex', quietly=TRUE)) {
      cat(format("  CPLEX optimizer is open..."), "\n")
      cat(format("  Finding the optimal matches..."), "\n")
      ptm = proc.time()
      out = Rcplex::Rcplex(objsense = 'max', cvec, Amat, bvec, sense = sense, vtype = vtype, n = 1, 
                           control = list(trace = trace, round = round_cplex, tilim = t_max))
      time = (proc.time()-ptm)[3]
      
      if (out$status==108) {
        cat(format("  Error: time limit exceeded, no integer solution!"), "\n")
        obj_total = NA
        obj_dist_mat = NA
        id = NA
        time = NA
      } else if (is.na(out$obj)) {
        cat(format("  Error: problem infeasible!"), "\n")
        obj_total = NA
        obj_dist_mat = NA
        id = NA=
          time = NA
      }
      
      if (!is.na(out$obj)) {
        cat(format("  Optimal matches found"), "\n")
        
        #! Matched units indexes
        id = (1:n_dec_vars)[out$xopt==1]
        
        #! Optimal value of the objective function
        obj_total = out$obj
        
      }
    } else {
      stop('Required solver not installed')
    }
    
  }
  
  #! GLPK
  else if (solver == "glpk") {
    #library(Rglpk)
    cat(format("  GLPK optimizer is open..."), "\n")
    dir = rep(NA, length(prmtrs$sense))
    dir[prmtrs$sense=="E"] = '=='
    dir[prmtrs$sense=="L"] = '<='
    dir[prmtrs$sense=="G"] = '>='
    
    cat(format("  Finding the optimal matches..."), "\n")
    ptm = proc.time()
    out= Rglpk_solve_LP(cvec, Amat, dir, bvec, types = vtype, max = TRUE)
    time = (proc.time()-ptm)[3]
    
    if (out$status!=0) {
      cat(format("  Error: problem infeasible!"), "\n")
      obj_total = NA
      obj_dist_mat = NA
      id = NA
      time = NA
    }
    
    if (out$status==0) {
      cat(format("  Optimal matches found"), "\n")
      
      #! Matched units indexes
      id = (1:n_dec_vars)[t_ind==1 & out$solution==1]
      
      #! Optimal value of the objective function
      obj_total = out$optimum
      
    }
  }
  
  #! Symphony
  else {
    #library(Rsymphony)
    if (requireNamespace('Rsymphony', quietly=TRUE)) {
      cat(format("  Symphony optimizer is open..."), "\n")
      
      dir = rep(NA, length(prmtrs$sense))
      dir[prmtrs$sense=="E"] = '=='
      dir[prmtrs$sense=="L"] = '<='
      dir[prmtrs$sense=="G"] = '>='
      
      cat(format("  Finding the optimal matches..."), "\n")
      ptm = proc.time()
      out= Rsymphony::Rsymphony_solve_LP(cvec, Amat, dir, bvec, types = vtype, max = TRUE, time_limit = t_max)
      time = (proc.time()-ptm)[3]
      
      if (out$status==228) {
        cat(format("  Error: problem exceeded the time limit and no feasible solution is found!"), "\n")
        obj_total = NA
        obj_dist_mat = NA
        id = NA
        time = NA
      }
      else if (out$status!=0) {
        cat(format("  Error: problem infeasible!"), "\n")
        obj_total = NA
        obj_dist_mat = NA
        id = NA
        time = NA
      }
      
      if (out$status==0) {
        cat(format("  Optimal matches found"), "\n")
        
        #! Matched units indexes
        id = (1:n_dec_vars)[out$solution==1]
        
        #! Optimal value of the objective function
        obj_total = out$objval
        
      }
    } else {
      stop('Required solver not installed')
    }
    
  }
  #! Output
  return(list(obj_total = obj_total, id = id, time = time))
}

#! Generate the parameters for cardmatch
.problemparameters_profmatch = function(mom_covs, mom_tols, mom_targets, fine_covs) {
  
  #! Number of units
  n = nrow(mom_covs)
  
  #! Number of dec. vars.
  n_dec_vars = n
  
  #! Coeffs. of the obj. fun., cvec
  cvec = c(rep(1, n))
  
  #! Constraint matrix, Amat
  row_ind_cur = 0
  #! Mom balance
  rows_mom = NULL
  cols_mom = NULL
  vals_mom = NULL
  n_mom_covs = ncol(mom_covs)
  k = 1
  for (i in 1:n_mom_covs) {
    #! Treated
    rows_mom_plus = rep(row_ind_cur+k, n)
    rows_mom_minus = rep(row_ind_cur+k+1, n)  
    rows_mom = c(rows_mom, rows_mom_plus, rows_mom_minus)
    cols_mom = c(cols_mom, rep(1:n, 2))
    vals_plus = c(mom_covs[, i]-mom_targets[i]-mom_tols[i])
    vals_minus = c(mom_covs[, i]-mom_targets[i]+mom_tols[i])
    vals_mom = c(vals_mom, c(vals_plus, vals_minus)) 
    k = k+2
  }
  row_ind_cur = max(rows_mom)
  
  #! Mom balance
  
  rows_ind = c(rows_mom)
  cols_ind = c(cols_mom)
  vals = c(vals_mom)
  
  aux = cbind(rows_ind, cols_ind, vals)[order(cols_ind), ]
  Amat = simple_triplet_matrix(i = aux[, 1], j = aux[, 2], v = aux[, 3])
  
  #! Constraint vector, bvec
  bvec = NULL
  #! Mom balance
  bvec_mom = rep(0, length(unique(rows_mom)))
  bvec = c(bvec, bvec_mom)
  
  #! Sense, sense
  sense = NULL
  
  #! Mom balance
  sense_covs = rep(c("L", "G"), length(unique(rows_mom))/2)
  sense = c(sense, sense_covs)
  
  #! Variable types, vtype
  vtype = rep("B", n_dec_vars)
  
  # Output
  return(list(n = n, 
              n_dec_vars = n_dec_vars,
              cvec = cvec, 
              Amat = Amat, 
              bvec = bvec, 
              sense = sense,
              vtype = vtype))
  
}

# profmatch
profmatch = function(t_ind, mom, solver = NULL) {
  
  mom_covs = mom$covs
  mom_tols = mom$tols
  mom_targets = mom$targets
  
  levels <- unique(t_ind)
  nlevels <- length(levels)
  
  objlist <- vector("list", nlevels)
  idlist <- vector("list", nlevels)
  timelist <- vector("list", nlevels)
  
  ids <- 1:nrow(mom$covs)
  for (j in 1:nlevels){
    level <- levels[j]
    .ids <- ids[which(t_ind == level)]
    out <- .oneprob_profmatch(level, t_ind, mom, solver)
    objlist[[j]] <- out$obj_total
    idlist[[j]] <- .ids[out$id]
    timelist[[j]] <- out$time
  }
  ids <- NULL
  obj_totals <- vector("numeric", nlevels)
  times <- vector("numeric", nlevels)
  for (j in 1:nlevels){
    ids <- c(ids, idlist[[j]])
    obj_totals[j] <- objlist[[j]]
    times[j] <- timelist[[j]]
  }
  
  out <- list(obj_totals = obj_totals, id = ids, times = times, t_ind = t_ind, mom = mom, solver = solver)

  #! Output
  return(out)
}
```

```{r setup, include=FALSE}
start_time <- Sys.time()
# Vector of treatment group indicators
t_ind = test_data$y
# Covariate matrix
mom_covs = as.matrix(lalonde[, covs])
X_mat = test_data[,-1]
X_mat_sds = apply(X_mat, 2, sd)
X_tols = 0.05 * X_mat_sds
X_targets = colMeans(X_mat)
# Putting it all together
mom = list(covs = X_mat, tols = X_tols, targets = X_targets)
t_max = 60*30
solver = "gurobi"
approximate = 0
solver = list(name = solver, t_max = t_max, approximate = approximate, round_cplex = 0, trace = 0)
# Performing profile matching
pmatch_out = profmatch(t_ind, mom, solver)
end_time <- Sys.time()
end_time - start_time
# Indices of the treated units and matched controls
t_id = pmatch_out$t_id
cat("Number of Matches:", length(t_id), "\n") #gives the total number of matches
```

# Simulate Data 

## Matching
Simulation for Matching:

```{r}
samp_data <- function(seed=293, sampsize=100, paramrep=3){
  # This function extends the feature matrix according to Hainmueller (2012)
  # Where every set of 6 columns is generated in the same way as Hainmueller
  # PARAMETERS:
  # seed: sets the seed for the random generator
  # sampsize: the sample size generated by the function
  # paramrep: sets the number of repeated sets of 6 generated by the sample data
  # sets the random seed
  set.seed(seed)
  
  # generates MVN covariance matrix for Hainmueller (2012)
  sigmainit <- matrix(c(2, 1, -1, 1, 1, -0.5, -1, -0.5, 1), ncol=3, nrow=3)
  temp <- lapply(seq_len(paramrep), function(X) sigmainit)
  sigmamatrix <- bdiag(temp)
  
  # as.matrix is needed because bdiag is a sparse matrix
  m_norm <- rmvnorm(sampsize, mean = rep(0, paramrep*3), sigma = as.matrix(sigmamatrix))
  
  # generates uniform, chi-squared, and binomial data
  m_unif <- matrix(runif(sampsize*paramrep, min=-3, max=3), nrow=sampsize, ncol=paramrep)
  m_chisq <- matrix(rchisq(sampsize*paramrep, df=1), nrow=sampsize, ncol=paramrep)
  m_binom <- matrix(rbinom(sampsize*paramrep, size=1, prob=0.5), nrow=sampsize, ncol=paramrep)
  
  # returns the dataset
  return(data.frame(cbind(m_norm, m_unif, m_chisq, m_binom)))
}
```

Data Generation for Matching:
```{r, eval=FALSE}
# Similar to the parameters in samp_data, but now, we also have a 
# treated_prob parameter, which gives the odds that an obs is
# note: parameters not contained here: this is mainly used to copy/paste for
# constructing other matching method simulations
set.seed(seed)
y <- rbinom(sampsize, size=1, prob=treated_prob)
test_data <- cbind(y, samp_data(seed=seed, sampsize=sampsize, paramrep=paramrep))
```


# Matching Comparisons

## BMatch

### Simulation Code for BMatch:
```{r}
#################################
# Minimum Distance Matching Simulation
#################################
# The goal here is to minimize the total of distances between matched pairs. In
# this example there are no covariate balance requirements. Again, the solver
# used is glpk with the approximate option
simbmatch <- function(sampsize=100, paramrep=1, treated_prob=0.2, 
                      seed=293, numtrials=5)
{
  # sampsize, paramrep have same functionality as in samp_data
  # treated_prob is the random prob of getting treatment
  # numtrials is the number of trials
  # Records Times, Matches
  times <- numeric(numtrials)
  nummatch <- numeric(numtrials)
  
  # For Every Trial:
  for(tempseed in c(seed:(seed+numtrials-1))){
    ### DATA GENERAION ###
    # Treatment Indicator
    set.seed(tempseed)
    t_ind <- rbinom(sampsize, size=1, prob=treated_prob)
    
    # Matrix of Covariates
    X_mat = samp_data(seed=tempseed, sampsize=sampsize, paramrep=paramrep)
    
    ### BMATCH BEGINS ###
    start_time <- Sys.time()
    
    # Distance matrix
    dist_mat = distmat(t_ind, X_mat)
    
    # Total pairs to be matched
    total_groups = sum(t_ind)
    
    # Solver options
    t_max = 60*5
    solver = "glpk"
    approximate = 1
    solver = list(name = solver, t_max = t_max, approximate = approximate,
                  round_cplex = 0, trace_cplex = 0)
    
    # Match!
    out = bmatch(t_ind = t_ind, dist_mat = dist_mat,
                 total_groups = total_groups, solver = solver)
    
    # record times + matches
    end_time <- Sys.time()
    times[tempseed-seed+1] <- end_time - start_time
    nummatch[tempseed-seed+1] <- length(out$t_id) + length(out$c_id)
    
    # for figuring out the units
    if(tempseed == seed){
      print(end_time - start_time)
    }
  }
  return(data.frame(cbind(times, nummatch)))
}
```

### Simulations:

Note: the parameters need to be manually changed, in case there is a memory overflow.
```{r}
results2 = simbmatch(sampsize=3000, paramrep=600, numtrials=1)
cat("Mean Time:", mean(results2$times), "\n")
cat("SD Time:", sd(results2$times), "\n")
cat("Mean Matches:", mean(results2$nummatch))
```


## Cardmatch

### Simlation Code for Cardmatch:
```{r}
# cardmatch simulation
# using the same dataset as before, finely matches for discrete variables as well
simcmatch <- function(sampsize=100, paramrep=1, treated_prob=0.2, 
                      seed=293, numtrials=5){
  # find tot # of parameters
  numparams <- paramrep*6
  
  # records # times, matches
  times <- numeric(numtrials)
  nummatch <- numeric(numtrials)
  
  # for every trial:
  for(tempseed in c(seed:(seed+numtrials-1))){
    ### DATA GENERAION ###
    set.seed(tempseed)
    y <- rbinom(sampsize, size=1, prob=treated_prob)
    test_data <- cbind(y, samp_data(seed=tempseed, sampsize=sampsize, 
                                    paramrep=paramrep))
    
    ### CARDMATCH BEGINS ###
    start_time <- Sys.time()
    
    # Load, sort, and attach data
    test_data = test_data[order(test_data$y, decreasing = TRUE),]
    
    # Treatment indicator; note that the data needs to be sorted in decreasing order
    # according to this treatment indicator
    t_ind = test_data$y
    
    # Moment Balance
    mom_covs = as.matrix(test_data %>% 
                           dplyr::select(paste("X", c(1:(numparams-paramrep)), sep="")))
    mom_tols = round(absstddif(mom_covs, t_ind, .05), 2)
    mom = list(covs = mom_covs, tols = mom_tols)
    
    # Fine balance
    fine_covs = as.matrix(test_data %>% 
                            dplyr::select(paste("X", c((numparams-paramrep+1):numparams), sep="")))
    fine = list(covs = fine_covs)
    
    # Solver options
    solver = "glpk"
    approximate = 1 # not exact!
    t_max = 60*5 # 5 minute maximum
    solver = list(name = solver, approximate = approximate, t_max = t_max,
                  round_cplex = 0, trace = 0)
    
    # Match!
    out = cardmatch(t_ind, mom = mom, fine = fine, solver = solver)
    
    # record times + matches
    end_time <- Sys.time()
    times[tempseed-seed+1] <- end_time - start_time
    nummatch[tempseed-seed+1] <- length(out$t_id) + length(out$c_id)
    
    # for figuring out the units
    
    print(end_time - start_time)
  }
  return(data.frame(cbind(times, nummatch)))
}
```

### Simulations:

Note: the parameters need to be manually changed, in case there is a memory overflow.
```{r}
results = simcmatch(sampsize=5000, paramrep=9, numtrials=3)
cat("Mean Time:", mean(results$times), "\n")
cat("SD Time:", sd(results$times), "\n")
cat("Mean Matches:", mean(results$nummatch))
results
```

```{r}
results[4,1] <- results[4,1]*60
```

## ProfMatch

# Feature Selection Comparisons

## Data Generation

insufficient as var.list is used later on too
```{r}
samp_data_feat <- function(seed=293, mean_x=0, sig_x=1, rho=0, n=500, 
                           stro=0.6, stre=1, bA=0){
  set.seed(seed)
  # mean_x: mean of x
  # sig_x: sd of x
  # rho: correlation between features from MVN
  # in paper, tried rho =0, 0.2, 0.5
  # n: sample size
  # p: total number of predictors
  # pC: true confounders
  # pI: in outcome, not in exposure model
  # pP: in exposure but not outcome
  # stro: strength of relationship between covariates and outcome
  # stre: strength of relationship between covariates and treatment
  # bA: true average treatment effect
  
  # pS: # of spurious covariates
  pS = p - (pC+pI+pP)
  
  # Set relationship between covariates and outcome
  beta_v = c(rep(stro, pC + pI), rep(0, pS + pP))
  # Y = \eta A + b'X + e
  # Set relationship between covariates and treatment
  alpha_v = c(rep(stre, pC), rep(0, pI), rep(stre, pP), rep(0, pS))
  # logit(P(A)) = v'X
  
  var.list = c(paste("Xc",1:pC,sep=""), paste("Xp",1:pP,sep=""), 
               paste("Xi",1:pI,sep=""), paste("Xs",1:pS,sep=""))
  names(beta_v) = names(alpha_v) = var.list

  ### simulate data
  # generate features:
  Sigma_x = matrix(rho*sig_x^2, nrow=p, ncol=p) 
  diag(Sigma_x) = sig_x^2
  Mean_x = rep(mean_x, p)
  Data = as.data.frame(mvrnorm(n = n, mu=Mean_x, Sigma = Sigma_x, empirical = FALSE))
  names(Data) = var.list
  # generate treatment:
  gA_x = rowSums(Data[,var.list]*matrix(alpha_v, nrow=n, ncol=p, byrow=TRUE))
  pA = expit(gA_x)
  Data$A = as.numeric(runif(n=length(pA)) < pA) # simulate A 
  # generate outcomes:
  gY_xA = rowSums(Data[,var.list]*matrix(beta_v, nrow=n, ncol=p, byrow=TRUE))   
  Data$Y = gY_xA + rnorm(n=n,sd=sig_x)
  Data$Y = Data$Y + Data$A*bA
  return(Data) 
}
```


## OAL

```{r}
#### PARAMETERS ####
seed = 293
mean_x = 0 
sig_x = 1
rho = 0
n = 1000
p = 20
pC = 2
pI = 2
pP = 2
pS = p - (pC+pI+pP)
stro = 0.6
stre = 1
bA = 0
numtrials = 5
lambda_vec = c(-10, -5, -2, -1, -0.75, -0.5, -0.25, 0.25, 0.49)
gamma_convergence_factor = 2
tolerance = 1/10^8

# seed: seed for randomization
# mean_x, sig_x: mean, sd of X covariate
# rho: correlation between features from MVN
# in paper, tried rho =0, 0.2, 0.5
# n: sample size
# p: # of predictors
# pC = # of True Confounders (both outcome + exposure)
# pI = In outcome model but not exposure model
# pP = In exposure but not outcome
# pS = spurious covariates
# stro: strength of relationship between covariates and outcome
# stre: strength of relationship between covariates and treatment
# bA: true average treatment effect
# numtrials: number of trials needed
# lambda_vec: set vector of possible lambda's to try (taken from S+E)
# gamma_convergence_factor: see paper
# tolerance: the cutoff for which variables are selected to either be in
#            the model or not; cutoff chosen from the paper

set.seed(seed)
defaultW <- getOption("warn") 
options(warn = -1) # to stop warnings about non-list contrasts

# Set relationship between covariates and outcome
beta_v = c(rep(stro, pC + pI), rep(0, pS + pP))
# Y = \eta A + b'X + e
# Set relationship between covariates and treatment
alpha_v = c(rep(stre, pC), rep(0, pI), rep(stre, pP), rep(0, pS))
# logit(P(A)) = v'X


var.list = c(paste("Xc",1:pC,sep=""), paste("Xp",1:pP,sep=""), 
             paste("Xi",1:pI,sep=""), paste("Xs",1:pS,sep=""))
names(beta_v) = names(alpha_v) = var.list

# records # times, covariates selected
times <- numeric(numtrials)
numsel <- matrix(rep(0, numtrials*4), nrow = numtrials, ncol=4)

# cycle for every trial
for(trial in c(1:numtrials))
{

  #### SIMULATE DATA ####
  # features:
  Sigma_x = matrix(rho*sig_x^2, nrow=p, ncol=p) 
  diag(Sigma_x) = sig_x^2
  Mean_x = rep(mean_x, p)
  Data = as.data.frame(mvrnorm(n = n, mu=Mean_x, Sigma = Sigma_x, 
                               empirical = FALSE))
  names(Data) = var.list
  # treatment:
  gA_x = rowSums(Data[,var.list]*matrix(alpha_v, nrow=n, ncol=p, byrow=TRUE))
  pA = expit(gA_x)
  Data$A = as.numeric(runif(n=length(pA)) < pA)
  # generate outcomes:
  gY_xA = rowSums(Data[,var.list]*matrix(beta_v, nrow=n, ncol=p, byrow=TRUE))
  Data$Y = gY_xA + rnorm(n=n,sd=sig_x)
  Data$Y = Data$Y + Data$A*bA
  
  
  ##### BEGIN OAL SIMS #####
  start_time <- Sys.time()
  
  names(lambda_vec) = as.character(lambda_vec)
  # get the gamma value for each value in the lambda vector that corresponds to convergence factor
  gamma_vals = 2*(gamma_convergence_factor - lambda_vec + 1)
  names(gamma_vals) = names(lambda_vec)
  
  # Normlize covariates to have mean 0 and standard deviation 1
  temp.mean = colMeans(Data[,var.list])
  Temp.mean = matrix(temp.mean, ncol=length(var.list), nrow=nrow(Data), byrow=TRUE)
  Data[,var.list] = Data[,var.list] - Temp.mean
  temp.sd = apply(Data[var.list], FUN=sd, MARGIN=2)
  Temp.sd = matrix(temp.sd, ncol=length(var.list), nrow=nrow(Data), byrow=TRUE)
  Data[var.list] = Data[,var.list] / Temp.sd
  rm(list=c("temp.mean","Temp.mean","temp.sd","Temp.sd"))
  
  # estimate outcome model
  y.form = formula(paste("Y~A+",paste(var.list,collapse="+")))
  lm.Y = lm(y.form,data=Data)
  betaXY = coef(lm.Y)[var.list] 
  
  ## Want to save ATE, wAMD and propensity score coefficients for each lambda value
  ATE = wAMD_vec = rep(NA, length(lambda_vec))
  names(ATE) = names(wAMD_vec) = names(lambda_vec)
  coeff_XA = as.data.frame(matrix(NA, nrow=length(var.list), ncol=length(lambda_vec)))
  names(coeff_XA) = names(lambda_vec)
  rownames(coeff_XA) = var.list
  
  ################################################################################
  #####  Run outcome adaptive lasso for each lambda value 
  ################################################################################
  # weight model with all possible covariates included, this is passed into lasso function
  w.full.form = formula(paste("A~",paste(var.list,collapse="+")))
  
  # loop through lambda values
  for(lil in names(lambda_vec)){
    il = lambda_vec[lil]
    ig = gamma_vals[lil]
  
    ### create the outcome adaptive lasso penalty with 
    ### coefficient specific weights determined by outcome model
    oal_pen = adaptive.lasso(lambda=n^(il), al.weights = abs(betaXY)^(-ig))
    
    ### run outcome-adaptive lasso model with appropriate penalty
    logit_oal = lqa.formula(w.full.form, data=Data, penalty=oal_pen, 
                            family=binomial(logit))
    
    # generate propensity score
    Data[,paste("f.pA",lil,sep="")] = predict(logit_oal)
    
    # save propensity score coefficients
    coeff_XA[var.list,lil] = coef(logit_oal)[var.list]
    
    # create inverse probability of treatment weights
    Data[,paste("w",lil,sep="")] = create_weights(fp=Data[,paste("f.pA",lil,sep="")], fA=Data$A)
    
    # estimate weighted absolute mean different over 
    # all covaraites using this lambda to generate weights
    wAMD_vec[lil] = wAMD_function(DataM=Data, varlist=var.list, trt.var="A",
  			                          wgt=paste("w",lil,sep=""), beta=betaXY)$wAMD
    
    # save ATE estimate for this lambda value
    ATE[lil] = ATE_est(fY=Data$Y,fw=Data[,paste("w",lil,sep="")],fA=Data$A)
  }
  
  # find the lambda value that creates the smallest wAMD
  tt = which.min(wAMD_vec)
  
  #### END OAL ####
  end_time <- Sys.time()
  times[trial] <- end_time - start_time
  
  # this is used to find the measurement of time
  if(trial == 1){
    print(end_time - start_time)
  }
  
  # select the coefficients for the propensity score that corresponds 
  # with smallest wAMD value
  final_coef = coeff_XA[,tt]
  
  # save proportion of covariates chosen
  numsel[trial,] = c(sum(final_coef[1:pC] > tolerance)/pC, 
                 sum(final_coef[(1+pC):(pC+pI)] > tolerance)/pI, 
                 sum(final_coef[(1+pC+pI):(pC+pI+pP)] > tolerance)/pP,
                 sum(final_coef[(1+pC+pI+pP):p] > tolerance)/pS)
}

# reset warning settings
options(warn = defaultW)

numsel = data.frame(numsel)
colnames(numsel) = c("C", "I", "P", "S")
cat("Mean Time:", mean(times), "\n")
cat("SD Time:", sd(times), "\n")
# print(numsel)
numsel %>% summarise_if(is.numeric, mean)

Data$A = as.numeric(Data$A)
class(Data$A)
typeof(Data$A)
```



