---
title: "293 Project Simulations"
author: "Jason"
date: '2022-04-10'
output: pdf_document
---

To-Dos:
- try other matching methods and compute their complexity
-- make sure profmatch works
NOTE: cplex code was commented out!
- need data generation method for feature variable selection
- try other feature variable selection methods
-- encode OAL

---
title: "Stat293"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup:

Packages:
```{r}```{r setup, include=FALSE}
# use (.packages()) to check if a package is properly loaded for your session
library("designmatch")
library("ggplot2")
library("mvtnorm")
library("Matrix")
library("dplyr")
library("lqa")
library("MASS")
```


## Shortreed and Ertefaie: OAL
Functions for Shortreed and Ertefaie's OAL:
```{r}```{r setup, include=FALSE}
### define some functions for generating data, ATE estimates, and the wAMD,
expit = function(x){ 
 pr = ( exp(x) / (1+exp(x)) ) 
 return(pr)
}
ATE_est = function(fY,fw,fA){
 t_ATE = fY*fw
 tt_ATE = ( ( sum(t_ATE[fA==1]) / sum(fw[fA==1]) ) - ( sum(t_ATE[fA==0]) /  sum(fw[fA==0]) ) )
 return(tt_ATE) 
}
create_weights = function(fp,fA,fw){
 fw = (fp)^(-1)
 fw[fA==0] = (1 - fp[fA==0])^(-1)
 return(fw)
}
wAMD_function = function(DataM,varlist,trt.var,wgt,beta){
 trt = untrt = diff_vec = rep(NA,length(beta)) 
 names(trt) = names(untrt) = names(diff_vec) = varlist
 for(jj in 1:length(varlist)){ 
  this.var = paste("w",varlist[jj],sep="") 
  DataM[,this.var] = DataM[,varlist[jj]] * DataM[,wgt] 
  trt[jj] = sum( DataM[DataM[,trt.var]==1, this.var ]) / sum(DataM[DataM[,trt.var]==1, wgt]) 
  untrt[jj] = sum(DataM[DataM[,trt.var]==0, this.var]) / sum(DataM[DataM[,trt.var]==0, wgt]) 
  diff_vec[jj] = abs( trt[jj] - untrt[jj] ) 
 } 
 wdiff_vec = diff_vec * abs(beta) 
 wAMD = c( sum(wdiff_vec))
 ret = list( diff_vec = diff_vec, wdiff_vec = wdiff_vec, wAMD = wAMD )
 return(ret) 
}
```

## ProfMatch function

```{r}```{r setup, include=FALSE}
# From Eric's paper
.oneprob_profmatch <- function(level, t_ind, mom, solver){
  mom_covs <- mom$covs
  mom_tols <- mom$tols
  mom_targets <- mom$targets
  
  if (is.null(solver)) {
    solver = 'glpk'
    t_max = 60 * 15
    approximate = 1
  } else {
    t_max = solver$t_max
    approximate = solver$approximate
    trace = solver$trace
    round_cplex = solver$round_cplex
    solver = solver$name
  }
  
  .mom_covs <- mom_covs[which(t_ind == level),]
  
  #! Generate the parameters
  cat(format("  Building the matching problem..."), "\n")
  prmtrs = .problemparameters_profmatch(.mom_covs, mom_tols, mom_targets)
  
  n = prmtrs$n
  n_dec_vars = prmtrs$n_dec_vars
  cvec = prmtrs$cvec
  Amat = prmtrs$Amat
  bvec = prmtrs$bvec
  sense = prmtrs$sense
  vtype = prmtrs$vtype
  
  #! Find matches and calculate the elapsed time
  #! Gurobi
  if (solver == "gurobi") {
    #library(gurobi)
    if (requireNamespace('gurobi', quietly=TRUE)) {
      cat(format("  Gurobi optimizer is open..."), "\n")
      model = list()
      model$modelsense = 'max'
      model$obj = cvec
      model$A = Amat
      model$sense = rep(NA, length(sense))
      model$sense[sense=="E"] = '='
      model$sense[sense=="L"] = '<='
      model$sense[sense=="G"] = '>='
      model$rhs = bvec
      model$vtypes = vtype
      
      t_lim = list(TimeLimit = t_max, OutputFlag = trace)
      
      cat(format("  Finding the optimal matches..."), "\n")
      ptm = proc.time()
      out = gurobi::gurobi(model, t_lim)
      time = (proc.time()-ptm)[3]
      
      if (out$status == "INFEASIBLE") {
        cat(format("  Error: problem infeasible!"), "\n")
        obj_total = NA
        obj_dist_mat = NA
        id = NA
        time = NA
      }
      
      if (out$status ==  "OPTIMAL" || out$status == "TIME_LIMIT") {
        if (out$status == "OPTIMAL") {
          cat(format("  Optimal matches found"), "\n")
        }
        
        else {
          cat(format("  Time limit reached, best suboptimal solution given"), "\n")
        }
        
        #! Matched units indexes
        id = (1:n_dec_vars)[out$x==1]
        
        #! Optimal value of the objective function
        obj_total = out$objval   
      }
    } else {
      stop('Required solver not installed')
    }
    
  }
  
  #! CPLEX
  else if (solver == "cplex") {
    #library(Rcplex)
    if (requireNamespace('Rcplex', quietly=TRUE)) {
      cat(format("  CPLEX optimizer is open..."), "\n")
      cat(format("  Finding the optimal matches..."), "\n")
      ptm = proc.time()
      out = Rcplex::Rcplex(objsense = 'max', cvec, Amat, bvec, sense = sense, vtype = vtype, n = 1, 
                           control = list(trace = trace, round = round_cplex, tilim = t_max))
      time = (proc.time()-ptm)[3]
      
      if (out$status==108) {
        cat(format("  Error: time limit exceeded, no integer solution!"), "\n")
        obj_total = NA
        obj_dist_mat = NA
        id = NA
        time = NA
      } else if (is.na(out$obj)) {
        cat(format("  Error: problem infeasible!"), "\n")
        obj_total = NA
        obj_dist_mat = NA
        id = NA=
          time = NA
      }
      
      if (!is.na(out$obj)) {
        cat(format("  Optimal matches found"), "\n")
        
        #! Matched units indexes
        id = (1:n_dec_vars)[out$xopt==1]
        
        #! Optimal value of the objective function
        obj_total = out$obj
        
      }
    } else {
      stop('Required solver not installed')
    }
    
  }
  
  #! GLPK
  else if (solver == "glpk") {
    #library(Rglpk)
    cat(format("  GLPK optimizer is open..."), "\n")
    dir = rep(NA, length(prmtrs$sense))
    dir[prmtrs$sense=="E"] = '=='
    dir[prmtrs$sense=="L"] = '<='
    dir[prmtrs$sense=="G"] = '>='
    
    cat(format("  Finding the optimal matches..."), "\n")
    ptm = proc.time()
    out= Rglpk_solve_LP(cvec, Amat, dir, bvec, types = vtype, max = TRUE)
    time = (proc.time()-ptm)[3]
    
    if (out$status!=0) {
      cat(format("  Error: problem infeasible!"), "\n")
      obj_total = NA
      obj_dist_mat = NA
      id = NA
      time = NA
    }
    
    if (out$status==0) {
      cat(format("  Optimal matches found"), "\n")
      
      #! Matched units indexes
      id = (1:n_dec_vars)[t_ind==1 & out$solution==1]
      
      #! Optimal value of the objective function
      obj_total = out$optimum
      
    }
  }
  
  #! Symphony
  else {
    #library(Rsymphony)
    if (requireNamespace('Rsymphony', quietly=TRUE)) {
      cat(format("  Symphony optimizer is open..."), "\n")
      
      dir = rep(NA, length(prmtrs$sense))
      dir[prmtrs$sense=="E"] = '=='
      dir[prmtrs$sense=="L"] = '<='
      dir[prmtrs$sense=="G"] = '>='
      
      cat(format("  Finding the optimal matches..."), "\n")
      ptm = proc.time()
      out= Rsymphony::Rsymphony_solve_LP(cvec, Amat, dir, bvec, types = vtype, max = TRUE, time_limit = t_max)
      time = (proc.time()-ptm)[3]
      
      if (out$status==228) {
        cat(format("  Error: problem exceeded the time limit and no feasible solution is found!"), "\n")
        obj_total = NA
        obj_dist_mat = NA
        id = NA
        time = NA
      }
      else if (out$status!=0) {
        cat(format("  Error: problem infeasible!"), "\n")
        obj_total = NA
        obj_dist_mat = NA
        id = NA
        time = NA
      }
      
      if (out$status==0) {
        cat(format("  Optimal matches found"), "\n")
        
        #! Matched units indexes
        id = (1:n_dec_vars)[out$solution==1]
        
        #! Optimal value of the objective function
        obj_total = out$objval
        
      }
    } else {
      stop('Required solver not installed')
    }
    
  }
  #! Output
  return(list(obj_total = obj_total, id = id, time = time))
}

#! Generate the parameters for cardmatch
.problemparameters_profmatch = function(mom_covs, mom_tols, mom_targets, fine_covs) {
  
  #! Number of units
  n = nrow(mom_covs)
  
  #! Number of dec. vars.
  n_dec_vars = n
  
  #! Coeffs. of the obj. fun., cvec
  cvec = c(rep(1, n))
  
  #! Constraint matrix, Amat
  row_ind_cur = 0
  #! Mom balance
  rows_mom = NULL
  cols_mom = NULL
  vals_mom = NULL
  n_mom_covs = ncol(mom_covs)
  k = 1
  for (i in 1:n_mom_covs) {
    #! Treated
    rows_mom_plus = rep(row_ind_cur+k, n)
    rows_mom_minus = rep(row_ind_cur+k+1, n)  
    rows_mom = c(rows_mom, rows_mom_plus, rows_mom_minus)
    cols_mom = c(cols_mom, rep(1:n, 2))
    vals_plus = c(mom_covs[, i]-mom_targets[i]-mom_tols[i])
    vals_minus = c(mom_covs[, i]-mom_targets[i]+mom_tols[i])
    vals_mom = c(vals_mom, c(vals_plus, vals_minus)) 
    k = k+2
  }
  row_ind_cur = max(rows_mom)
  
  #! Mom balance
  
  rows_ind = c(rows_mom)
  cols_ind = c(cols_mom)
  vals = c(vals_mom)
  
  aux = cbind(rows_ind, cols_ind, vals)[order(cols_ind), ]
  Amat = simple_triplet_matrix(i = aux[, 1], j = aux[, 2], v = aux[, 3])
  
  #! Constraint vector, bvec
  bvec = NULL
  #! Mom balance
  bvec_mom = rep(0, length(unique(rows_mom)))
  bvec = c(bvec, bvec_mom)
  
  #! Sense, sense
  sense = NULL
  
  #! Mom balance
  sense_covs = rep(c("L", "G"), length(unique(rows_mom))/2)
  sense = c(sense, sense_covs)
  
  #! Variable types, vtype
  vtype = rep("B", n_dec_vars)
  
  # Output
  return(list(n = n, 
              n_dec_vars = n_dec_vars,
              cvec = cvec, 
              Amat = Amat, 
              bvec = bvec, 
              sense = sense,
              vtype = vtype))
  
}

# profmatch
profmatch = function(t_ind, mom, solver = NULL) {
  
  mom_covs = mom$covs
  mom_tols = mom$tols
  mom_targets = mom$targets
  
  levels <- unique(t_ind)
  nlevels <- length(levels)
  
  objlist <- vector("list", nlevels)
  idlist <- vector("list", nlevels)
  timelist <- vector("list", nlevels)
  
  ids <- 1:nrow(mom$covs)
  for (j in 1:nlevels){
    level <- levels[j]
    .ids <- ids[which(t_ind == level)]
    out <- .oneprob_profmatch(level, t_ind, mom, solver)
    objlist[[j]] <- out$obj_total
    idlist[[j]] <- .ids[out$id]
    timelist[[j]] <- out$time
  }
  ids <- NULL
  obj_totals <- vector("numeric", nlevels)
  times <- vector("numeric", nlevels)
  for (j in 1:nlevels){
    ids <- c(ids, idlist[[j]])
    obj_totals[j] <- objlist[[j]]
    times[j] <- timelist[[j]]
  }
  
  out <- list(obj_totals = obj_totals, id = ids, times = times, t_ind = t_ind, mom = mom, solver = solver)

  #! Output
  return(out)
}
```

```{r}```{r setup, include=FALSE}
library(designmatch)
start_time <- Sys.time()
# Vector of treatment group indicators
t_ind = test_data$y
# Covariate matrix
mom_covs = as.matrix(lalonde[, covs])
X_mat = test_data[,-1]
X_mat_sds = apply(X_mat, 2, sd)
X_tols = 0.05 * X_mat_sds
X_targets = colMeans(X_mat)
# Putting it all together
mom = list(covs = X_mat, tols = X_tols, targets = X_targets)
t_max = 60*30
solver = "gurobi"
approximate = 0
solver = list(name = solver, t_max = t_max, approximate = approximate, round_cplex = 0, trace = 0)
# Performing profile matching
pmatch_out = profmatch(t_ind, mom, solver)
end_time <- Sys.time()
end_time - start_time
# Indices of the treated units and matched controls
t_id = pmatch_out$t_id
cat("Number of Matches:", length(t_id), "\n") #gives the total number of matches
```

# Simulate Data 

## Matching
Simulation for Matching:

```{r}
samp_data <- function(seed=293, sampsize=100, paramrep=3){
  # This function extends the feature matrix according to Hainmueller (2012)
  # Where every set of 6 columns is generated in the same way as Hainmueller
  # PARAMETERS:
  # seed: sets the seed for the random generator
  # sampsize: the sample size generated by the function
  # paramrep: sets the number of repeated sets of 6 generated by the sample data
  # sets the random seed
  set.seed(seed)
  
  # generates MVN covariance matrix for Hainmueller (2012)
  sigmainit <- matrix(c(2, 1, -1, 1, 1, -0.5, -1, -0.5, 1), ncol=3, nrow=3)
  temp <- lapply(seq_len(paramrep), function(X) sigmainit)
  sigmamatrix <- bdiag(temp)
  
  # as.matrix is needed because bdiag is a sparse matrix
  m_norm <- rmvnorm(sampsize, mean = rep(0, paramrep*3), sigma = as.matrix(sigmamatrix))
  
  # generates uniform, chi-squared, and binomial data
  m_unif <- matrix(runif(sampsize*paramrep, min=-3, max=3), nrow=sampsize, ncol=paramrep)
  m_chisq <- matrix(rchisq(sampsize*paramrep, df=1), nrow=sampsize, ncol=paramrep)
  m_binom <- matrix(rbinom(sampsize*paramrep, size=1, prob=0.5), nrow=sampsize, ncol=paramrep)
  
  # returns the dataset
  return(data.frame(cbind(m_norm, m_unif, m_chisq, m_binom)))
}
```

Data Generation for Matching:
```{r}
library(Matrix)
library(mvtnorm)
sampsize <- 10000
seed <- 293
paramrep <- 1
numparams <- paramrep*6
treated_prob <- 0.2
# Similar to the parameters in samp_data, but now, we also have a 
# treated_prob parameter, which gives the odds that an obs is
set.seed(seed)
y <- rbinom(sampsize, size=1, prob=treated_prob)
test_data <- cbind(y, samp_data(seed=seed, sampsize=sampsize, paramrep=paramrep))
```


# Matching Comparisons

## BMatch

```{r}
#################################
# Example 2: minimum distance matching
################################# test_data[,-1]
# The goal here is to minimize the total of distances between matched pairs. In
# this example there are no covariate balance requirements. Again, the solver
# used is glpk with the approximate option
start_time <- Sys.time()
# Treatment indicator
t_ind = test_data$y
# Matrix of covariates
X_mat = test_data[,-1]
# Distance matrix
dist_mat = distmat(t_ind, X_mat)
# Subset matching weight
subset_weight = NULL
# Total pairs to be matched
total_groups = sum(t_ind)
# Solver options
t_max = 60*5
solver = "glpk"
approximate = 1
solver = list(name = solver, t_max = t_max, approximate = approximate,
round_cplex = 0, trace_cplex = 0)
# Match
out = bmatch(t_ind = t_ind, dist_mat = dist_mat, total_groups = total_groups,
solver = solver)
end_time <- Sys.time()
end_time - start_time
# Indices of the treated units and matched controls
t_id = out$t_id
cat("Number of Matches:", length(t_id), "\n") #gives the total number of matches
# Total of distances between matched pairs
out$obj_total
```



## Cardmatch
```{r}
start_time <- Sys.time()
# Load, sort, and attach data
test_data = test_data[order(test_data$y, decreasing = TRUE), ]
# Treatment indicator; note that the data needs to be sorted in decreasing order
# according to this treatment indicator
t_ind = test_data$y
# Moment Balance
mom_covs = as.matrix(test_data %>% dplyr::select(paste("X", c(1:(numparams - paramrep)), sep="")))
mom_tols = round(absstddif(mom_covs, t_ind, .05), 2)
mom = list(covs = mom_covs, tols = mom_tols)
# Fine balance
fine_covs = as.matrix(test_data %>% dplyr::select(paste("X", c((numparams-paramrep + 1):numparams), sep="")))
fine = list(covs = fine_covs)
# Solver options
solver = "glpk"
approximate = 1 # not exact!
t_max = 60*5 # 5 minute maximum
solver = list(name = solver, approximate = approximate, t_max = t_max,
round_cplex = 0, trace = 0)
# Match
out = cardmatch(t_ind, mom = mom, fine = fine, solver = solver)
end_time <- Sys.time()
end_time - start_time
# Indices of the treated units and matched controls
t_id = out$t_id
cat("Number of Matches:", length(t_id), "\n") #gives the total number of matches
```

## ProfMatch

# Feature Selection Comparisons


## OAL

```{r}
#### Problem Statment
mean_x = 0 
sig_x = 1
# correlation between features from MVN
# in paper, tried rho =0, 0.2, 0.5
rho = 0
# sample size
n = 500
# total number of predictors
p = 200
pC = pI = pP = 2
pS = p - (pC+pI+pP)
# pC = True Confounders (both outcome + exposure)
# pI = In outcome model but not exposure model
# pP = In exposure but not outcome
# rest = spurious covariates

# Set strength of relationship between covariates and outcome
beta_v =  c(0.6, 0.6, 0.6, 0.6, 0, 0, rep(0,p-6))
# Y = \eta A + b'X + e
# Set strength of relationship between covariates and treatment
alpha_v = c(1, 1, 0, 0, 1, 1,  rep(0,p-6))
# logit(P(A)) = v'X

### set true average treatment effect
bA = 0

### simulate data
Sigma_x = matrix(rho*sig_x^2,nrow=length(var.list),ncol=length(var.list)) 
diag(Sigma_x) = sig_x^2
Mean_x = rep(mean_x,length(var.list))
Data = as.data.frame(mvrnorm(n = n, mu=Mean_x, Sigma = Sigma_x, empirical = FALSE))
names(Data) = var.list
gA_x = rowSums(Data[,var.list]*matrix(alpha_v, nrow=n, ncol=length(var.list), byrow=TRUE))
pA = expit(gA_x)
Data$A = as.numeric(runif(n=length(pA)) < pA) # simulate A 
gY_xA = rowSums(Data[,var.list]*matrix(beta_v, nrow=n, ncol=length(var.list), byrow=TRUE))   
Data$Y = gY_xA + rnorm(n=n,sd=sig_x)
Data$Y = Data$Y + Data$A*bA

start_time <- Sys.time()
####### Begin setup for OAL
var.list = c(paste("Xc",1:pC,sep=""),paste("Xp",1:pP,sep=""),paste("Xi",1:pI,sep=""),paste("Xs",1:pS,sep=""))
names(beta_v) = names(alpha_v) = var.list

# set vector of possible lambda's to try
lambda_vec = c( -10, -5, -2, -1, -0.75, -0.5, -0.25, 0.25, 0.49)
names(lambda_vec) = as.character(lambda_vec)
# lambda_n (n)^(gamma/2 - 1) = n^(gamma_convergence_factor)
gamma_convergence_factor = 2
# get the gamma value for each value in the lambda vector that corresponds to convergence factor
gamma_vals = 2*(gamma_convergence_factor - lambda_vec + 1)
names(gamma_vals) = names(lambda_vec)

# Normlize coviarates to have mean 0 and standard deviation 1
temp.mean = colMeans(Data[,var.list])
Temp.mean = matrix(temp.mean,ncol=length(var.list),nrow=nrow(Data),byrow=TRUE)
Data[,var.list] = Data[,var.list] - Temp.mean
temp.sd = apply(Data[var.list],FUN=sd,MARGIN=2)
Temp.sd = matrix(temp.sd,ncol=length(var.list),nrow=nrow(Data),byrow=TRUE)
Data[var.list] = Data[,var.list] / Temp.sd
rm(list=c("temp.mean","Temp.mean","temp.sd","Temp.sd"))

# estimate outcome model
y.form = formula(paste("Y~A+",paste(var.list,collapse="+")))
lm.Y = lm(y.form,data=Data)
betaXY = coef(lm.Y)[var.list] 

## Want to save ATE, wAMD and propensity score coefficients for each lambda value
ATE = wAMD_vec = rep(NA, length(lambda_vec))
names(ATE) = names(wAMD_vec) = names(lambda_vec)
coeff_XA = as.data.frame(matrix(NA,nrow=length(var.list),ncol=length(lambda_vec)))
names(coeff_XA) = names(lambda_vec)
rownames(coeff_XA) = var.list

######################################################################################
#####  Run outcome adaptive lasso for each lambda value 
######################################################################################
# weight model with all possible covariates included, this is passed into lasso function
w.full.form = formula(paste("A~",paste(var.list,collapse="+")))
# GOT ERROR:
# no applicable method for 'lqa' applied to an object of class "formula"
# decided to change lqa to lqa.formula to test it out
# then got: Error: $ operator is invalid for atomic vectors


for(lil in names(lambda_vec)){
  il = lambda_vec[lil]
  ig = gamma_vals[lil]

  ### create the outcome adaptive lasso penalty with coefficient specific weights determined by outcome model
  oal_pen = adaptive.lasso(lambda=n^(il), al.weights = abs(betaXY)^(-ig))
  
  ### run outcome-adaptive lasso model with appropriate penalty
  logit_oal = lqa.formula(w.full.form, data=Data, penalty=oal_pen, family=binomial(logit))
  
  # generate propensity score
  # ERROR-CHECKING:
  # lqa.formula generates the correct class of lqa
  # print(class(logit_oal))
  
  # CHANGED HERE from predict(logit_oal)$mu.new TO predict(logit_oal)
  # because this caused the original Error: $ operator is invalid for atomic vectors
  # Data[,paste("f.pA",lil,sep="")] = predict(logit_oal)$mu.new
  Data[,paste("f.pA",lil,sep="")] = predict(logit_oal)
  
  # save propensity score coefficients
  coeff_XA[var.list,lil] = coef(logit_oal)[var.list]
  
  # create inverse probability of treatment weights
  Data[,paste("w",lil,sep="")] = create_weights(fp=Data[,paste("f.pA",lil,sep="")],fA=Data$A)
  
  # estimate weighted absolute mean different over all covaraites using this lambda to generate weights
  wAMD_vec[lil] = wAMD_function(DataM=Data,varlist=var.list,trt.var="A",
			wgt=paste("w",lil,sep=""),beta=betaXY)$wAMD
  
  # save ATE estimate for this lambda value
  ATE[lil] = ATE_est(fY=Data$Y,fw=Data[,paste("w",lil,sep="")],fA=Data$A)
  
} # close loop through lambda values

# print out wAMD for all the lambda values tried
wAMD_vec
# find the lambda value that creates the smallest wAMD
tt = which.min(wAMD_vec)

### END OAL
end_time <- Sys.time()
end_time - start_time


# print out ATE corresponding to smallest wAMD value
# ATE[tt]
# print out the coefficients for the propensity score that corresponds with smallest wAMD value 
coeff_XA[,tt]

```


# Examples from Papers, Documentation, StackOverflow

## Timing:
```{r}
start_time <- Sys.time()
end_time <- Sys.time()
end_time - start_time
```

## Designmatch Example:
```{r}
data("lalonde", package = "designmatch")
covs = c("age", "education", "black", "hispanic", "married", "nodegree", "re74",
"re75")
mom_targets = colMeans(lalonde[, covs])
cov_sds = apply(lalonde[, covs], 2, sd)
mom_tols = 0.05 * cov_sds
t_ind = lalonde$treatment
mom_covs = as.matrix(lalonde[, covs])
mom = list(covs = mom_covs, tols = mom_tols, targets = mom_targets)
# Solver:
t_max = 60*30
solver = "gurobi"
approximate = 0
solver = list(name = solver, t_max = t_max, approximate = approximate, round_cplex = 0, trace = 0)
## Performing profile matching
pmatch_out = profmatch(t_ind, mom, solver)
## Selecting the units that are matched
lalonde_matched = lalonde[pmatch_out$id,]
```

## Example cardmatch:
```{r}
# Load, sort, and attach data
data(lalonde)
lalonde = lalonde[order(lalonde$treatment, decreasing = TRUE), ]
attach(lalonde)
#################################
# Example 1: cardinality matching
#################################
# Cardinality matching finds the largest matched sample of pairs that meets balance
# requirements. Here the balance requirements are mean balance, fine balance and
# exact matching for different covariates. The solver used is glpk with the
# approximate option.
# Treatment indicator; note that the data needs to be sorted in decreasing order
# according to this treatment indicator
t_ind = treatment
t_ind
# Distance matrix
dist_mat = NULL
# Subset matching weight
subset_weight = 1
# Moment balance: constrain differences in means to be at most .05 standard deviations apart
mom_covs = cbind(age, education, black, hispanic, married, nodegree, re74, re75)
mom_tols = round(absstddif(mom_covs, t_ind, .05), 2)
mom = list(covs = mom_covs, tols = mom_tols)
# Fine balance
fine_covs = cbind(black, hispanic, married, nodegree)
fine = list(covs = fine_covs)
# Exact matching
exact_covs = cbind(black)
exact = list(covs = exact_covs)
# Solver options
# t_max = 60*5 max time
solver = "glpk" # solver type
approximate = 1
solver = list(name = solver, approximate = approximate, # t_max = t_max
round_cplex = 0, trace = 0)
# Match
out = bmatch(t_ind = t_ind, dist_mat = dist_mat, subset_weight = subset_weight,
mom = mom, fine = fine, exact = exact, solver = solver)
# Indices of the treated units and matched controls
t_id = out$t_id
c_id = out$c_id
# Time
out$time/60
# Matched group identifier (who is matched to whom)
# out$group_id
# Assess mean balance
# meantab(mom_covs, t_ind, t_id, c_id)
# Assess fine balance (note here we are getting an approximate solution)
# for (i in 1:ncol(fine_covs)) {
# print(finetab(fine_covs[, i], t_id, c_id))
# }
# Assess exact matching balance
# table(exact_covs[t_id]==exact_covs[c_id])
```

## Example Cardmatch 2:

```{r}
# Load, sort, and attach data
data(lalonde)
lalonde = lalonde[order(lalonde$treatment, decreasing = TRUE), ]
attach(lalonde)
#################################
# Step 1: use cardinality matching to find the largest sample of matched pairs for which
# all the covariates are finely balanced.
#################################
# Discretize covariates
quantiles = function(covar, n_q) {
p_q = seq(0, 1, 1/n_q)
val_q = quantile(covar, probs = p_q, na.rm = TRUE)
covar_out = rep(NA, length(covar))
for (i in 1:n_q) {
if (i==1) {covar_out[covar<val_q[i+1]] = i}
if (i>1 & i<n_q) {covar_out[covar>=val_q[i] & covar<val_q[i+1]] = i}
if (i==n_q) {covar_out[covar>=val_q[i] & covar<=val_q[i+1]] = i}}
covar_out
}
age_5 = quantiles(age, 5)
education_5 = quantiles(education, 5)
re74_5 = quantiles(re74, 5)
re75_5 = quantiles(re75, 5)
# Treatment indicator; note that the data needs to be sorted in decreasing order
# according to this treatment indicator
t_ind = treatment
t_ind
# Fine balance
fine_covs = cbind(black, hispanic, married, nodegree, age_5, education_5, re74_5, re75_5)
typeof(fine_covs)
fine = list(covs = fine_covs)
# Solver options
t_max = 60*5
solver = "glpk"
approximate = 0
solver = list(name = solver, t_max = t_max, approximate = approximate,
round_cplex = 0, trace = 0)
# Match
out_1 = cardmatch(t_ind, fine = fine, solver = solver)
# Indices of the treated units and matched controls
t_id_1 = out_1$t_id
length(t_id_1)
# c_id_1 = out_1$c_id
# Mean balance
# covs = cbind(age, education, black, hispanic, married, nodegree, re74, re75)
# meantab(covs, t_ind, t_id_1, c_id_1)
# Fine balance (note here we are getting an approximate solution)
# for (i in 1:ncol(fine_covs)) {
# print(finetab(fine_covs[, i], t_id_1, c_id_1))
# }
```
